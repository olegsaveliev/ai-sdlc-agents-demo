name: QA Agent - Auto Test Generation

on:
  pull_request:
    types: [opened, synchronize]
  workflow_dispatch:

jobs:
  qa-agent:
    runs-on: ubuntu-latest
    permissions:
      pull-requests: write
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.ref || github.ref }}
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install anthropic requests pytest dnspython
          
          # Install app dependencies if requirements.txt exists
          if [ -f "requirements.txt" ]; then
            echo "üì¶ Installing from requirements.txt..."
            pip install -r requirements.txt
          fi

      - name: Copy Slack notifications module
        run: |
          if [ -f "slack_notifications.py" ]; then
            mkdir -p agents
            cp slack_notifications.py agents/
            echo "‚úÖ Copied slack_notifications.py"
          else
            echo "‚ö†Ô∏è slack_notifications.py not found"
          fi
      
      - name: Run QA Agent (without Slack notification)
        if: github.event.pull_request.number
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          PR_NUMBER: ${{ github.event.pull_request.number }}
          NOTION_TOKEN: ${{ secrets.NOTION_TOKEN }}
          NOTION_DATABASE_ID: ${{ secrets.NOTION_DATABASE_ID }}
          NOTION_METRICS_DB_ID: ${{ secrets.NOTION_METRICS_DB_ID }}
        run: |
          echo "ü§ñ Running QA Agent (test generation only)..."
          python agents/qa_agent.py
      
      - name: Run Generated Tests
        id: run_tests
        continue-on-error: true
        run: |
          # Create execution log
          echo "=== QA Agent Test Execution Log ===" > execution_log.txt
          echo "Date: $(date -u +"%Y-%m-%d %H:%M:%S UTC")" >> execution_log.txt
          echo "" >> execution_log.txt
          
          if [ -f "tests/test_generated.py" ]; then
            echo "üß™ Running generated tests..."
            export PYTHONPATH="${PYTHONPATH}:$(pwd)"
            
            # Log what we're about to do
            echo "Step 1: Setting up test environment" >> execution_log.txt
            echo "  - PYTHONPATH: ${PYTHONPATH}" >> execution_log.txt
            echo "  - Test file: tests/test_generated.py" >> execution_log.txt
            echo "" >> execution_log.txt
            
            # Show the generated test file content
            echo "Step 2: Generated test file content" >> execution_log.txt
            echo "----------------------------------------" >> execution_log.txt
            cat tests/test_generated.py >> execution_log.txt
            echo "----------------------------------------" >> execution_log.txt
            echo "" >> execution_log.txt
            
            # List all test functions
            echo "Step 3: Discovered test functions" >> execution_log.txt
            grep -n "def test_" tests/test_generated.py >> execution_log.txt || echo "  No test functions found" >> execution_log.txt
            echo "" >> execution_log.txt
            
            # Run pytest with verbose output
            echo "Step 4: Executing tests with pytest" >> execution_log.txt
            echo "Command: pytest tests/test_generated.py -v --tb=short" >> execution_log.txt
            echo "" >> execution_log.txt
            
            set +e
            pytest tests/test_generated.py -v --tb=short > test_results.txt 2>&1
            TEST_EXIT_CODE=$?
            set -e
            
            echo "exit_code=$TEST_EXIT_CODE" >> $GITHUB_OUTPUT
            
            # Log exit code
            echo "Step 5: Test execution completed" >> execution_log.txt
            echo "  Exit code: $TEST_EXIT_CODE" >> execution_log.txt
            if [ $TEST_EXIT_CODE -eq 0 ]; then
              echo "  Result: ‚úÖ All tests passed" >> execution_log.txt
            elif [ $TEST_EXIT_CODE -eq 1 ]; then
              echo "  Result: ‚ö†Ô∏è Some tests failed" >> execution_log.txt
            else
              echo "  Result: ‚ùå Test execution error" >> execution_log.txt
            fi
            echo "" >> execution_log.txt
            
            # Show results
            echo "--- Test Results ---"
            cat test_results.txt
            echo "--------------------"
            
            # Append results to execution log
            echo "Step 6: Test results" >> execution_log.txt
            echo "----------------------------------------" >> execution_log.txt
            cat test_results.txt >> execution_log.txt
            echo "----------------------------------------" >> execution_log.txt
            echo "" >> execution_log.txt
            
            # Parse individual test results
            echo "Step 7: Individual test results" >> execution_log.txt
            grep -E "test_.*PASSED|test_.*FAILED|test_.*ERROR" test_results.txt >> execution_log.txt || echo "  No individual results found" >> execution_log.txt
            echo "" >> execution_log.txt
            
            # Parse summary
            PASSED=$(grep -oP '\d+(?= passed)' test_results.txt | head -1 || echo "0")
            FAILED=$(grep -oP '\d+(?= failed)' test_results.txt | head -1 || echo "0")
            ERRORS=$(grep -oP '\d+(?= error)' test_results.txt | head -1 || echo "0")
            
            echo "passed=$PASSED" >> $GITHUB_OUTPUT
            echo "failed=$FAILED" >> $GITHUB_OUTPUT
            echo "errors=$ERRORS" >> $GITHUB_OUTPUT
            
            TOTAL=$((PASSED + FAILED + ERRORS))
            echo "total=$TOTAL" >> $GITHUB_OUTPUT
            
            if [ $TOTAL -gt 0 ]; then
              SUCCESS_RATE=$(awk "BEGIN {printf \"%.1f\", ($PASSED / $TOTAL) * 100}")
            else
              SUCCESS_RATE="0.0"
            fi
            echo "success_rate=$SUCCESS_RATE" >> $GITHUB_OUTPUT
            
            # Log summary
            echo "Step 8: Summary" >> execution_log.txt
            echo "  Total tests: $TOTAL" >> execution_log.txt
            echo "  Passed: $PASSED" >> execution_log.txt
            echo "  Failed: $FAILED" >> execution_log.txt
            echo "  Errors: $ERRORS" >> execution_log.txt
            echo "  Success rate: $SUCCESS_RATE%" >> execution_log.txt
            
            echo "üìä Results: $PASSED passed, $FAILED failed, $ERRORS errors (Total: $TOTAL)"
          else
            echo "‚ÑπÔ∏è No test file found" > test_results.txt
            echo "No tests were generated" > execution_log.txt
            echo "exit_code=0" >> $GITHUB_OUTPUT
            echo "passed=0" >> $GITHUB_OUTPUT
            echo "failed=0" >> $GITHUB_OUTPUT
            echo "errors=0" >> $GITHUB_OUTPUT
            echo "total=0" >> $GITHUB_OUTPUT
            echo "success_rate=0.0" >> $GITHUB_OUTPUT
          fi
      
      - name: Send Slack Notification with Results
        if: always()
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          PR_NUMBER: ${{ github.event.pull_request.number }}
          PR_TITLE: ${{ github.event.pull_request.title }}
          PASSED: ${{ steps.run_tests.outputs.passed }}
          FAILED: ${{ steps.run_tests.outputs.failed }}
          ERRORS: ${{ steps.run_tests.outputs.errors }}
          TOTAL: ${{ steps.run_tests.outputs.total }}
          SUCCESS_RATE: ${{ steps.run_tests.outputs.success_rate }}
        run: |
          if [ -z "$SLACK_WEBHOOK_URL" ]; then
            echo "‚ö†Ô∏è SLACK_WEBHOOK_URL not configured - skipping notification"
            exit 0
          fi
          
          python3 << 'SLACK_SCRIPT'
          import os
          import requests
          import json
          
          webhook_url = os.environ.get('SLACK_WEBHOOK_URL')
          if not webhook_url:
              print("‚ö†Ô∏è No Slack webhook URL - skipping")
              exit(0)
          
          pr_number = os.environ.get('PR_NUMBER', '0')
          pr_title = os.environ.get('PR_TITLE', 'Unknown PR')
          
          # Safe integer conversion with defaults
          passed = int(os.environ.get('PASSED', '0') or '0')
          failed = int(os.environ.get('FAILED', '0') or '0')
          errors = int(os.environ.get('ERRORS', '0') or '0')
          total = int(os.environ.get('TOTAL', '0') or '0')
          
          # Safe float conversion
          success_rate_str = os.environ.get('SUCCESS_RATE', '0.0') or '0.0'
          try:
              success_rate = float(success_rate_str)
          except ValueError:
              success_rate = 0.0
          
          # Determine status
          if total == 0:
              status = "‚è≠Ô∏è No Tests"
              color = "#808080"
          elif failed == 0 and errors == 0:
              status = "‚úÖ All Passed"
              color = "#36a64f"
          elif success_rate >= 80:
              status = "‚ö†Ô∏è Some Failures"
              color = "#ff9900"
          else:
              status = "‚ùå Many Failures"
              color = "#ff0000"
          
          # Build Slack message
          message = {
              "attachments": [
                  {
                      "color": color,
                      "blocks": [
                          {
                              "type": "header",
                              "text": {
                                  "type": "plain_text",
                                  "text": f"üß™ QA Agent Complete: PR #{pr_number}"
                              }
                          },
                          {
                              "type": "section",
                              "text": {
                                  "type": "mrkdwn",
                                  "text": f"*{pr_title}*\n{status}"
                              }
                          },
                          {
                              "type": "section",
                              "fields": [
                                  {
                                      "type": "mrkdwn",
                                      "text": f"*Tests Generated:*\nüìù {total} tests"
                                  },
                                  {
                                      "type": "mrkdwn",
                                      "text": f"*Success Rate:*\nüìä {success_rate}%"
                                  },
                                  {
                                      "type": "mrkdwn",
                                      "text": f"*Passed:*\n‚úÖ {passed}"
                                  },
                                  {
                                      "type": "mrkdwn",
                                      "text": f"*Failed:*\n‚ùå {failed}"
                                  }
                              ]
                          },
                          {
                              "type": "actions",
                              "elements": [
                                  {
                                      "type": "button",
                                      "text": {
                                          "type": "plain_text",
                                          "text": "View Pull Request"
                                      },
                                      "url": f"https://github.com/{os.environ.get('GITHUB_REPOSITORY', '')}/pull/{pr_number}"
                                  }
                              ]
                          }
                      ]
                  }
              ]
          }
          
          try:
              response = requests.post(
                  webhook_url,
                  json=message,
                  timeout=10
              )
              
              if response.status_code == 200:
                  print("‚úÖ Slack notification sent successfully!")
                  print(f"   Status: {status}")
                  print(f"   Tests: {passed}/{total} passed ({success_rate}%)")
              else:
                  print(f"‚ö†Ô∏è Slack notification failed: {response.status_code}")
                  print(f"Response: {response.text}")
          except Exception as e:
              print(f"‚ùå Error sending Slack notification: {e}")
          
          SLACK_SCRIPT
      
      - name: Post to GitHub and Notion
        if: always()
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          PR_NUMBER: ${{ github.event.pull_request.number }}
          NOTION_TOKEN: ${{ secrets.NOTION_TOKEN }}
          NOTION_DATABASE_ID: ${{ secrets.NOTION_DATABASE_ID }}
          PASSED: ${{ steps.run_tests.outputs.passed }}
          FAILED: ${{ steps.run_tests.outputs.failed }}
          ERRORS: ${{ steps.run_tests.outputs.errors }}
          TOTAL: ${{ steps.run_tests.outputs.total }}
          SUCCESS_RATE: ${{ steps.run_tests.outputs.success_rate }}
        run: |
          python3 << 'PYTHON_SCRIPT'
          import os
          import requests
          from datetime import datetime
          import re
          
          # Read test results
          try:
              with open('test_results.txt', 'r') as f:
                  test_results = f.read()
          except FileNotFoundError:
              test_results = "No test results available"
          
          # Read execution log
          try:
              with open('execution_log.txt', 'r') as f:
                  execution_log = f.read()
          except FileNotFoundError:
              execution_log = "No execution log available"
          
          # Get metrics from environment with safe defaults
          passed = int(os.environ.get('PASSED', '0') or '0')
          failed = int(os.environ.get('FAILED', '0') or '0')
          errors = int(os.environ.get('ERRORS', '0') or '0')
          total = int(os.environ.get('TOTAL', '0') or '0')
          
          success_rate_str = os.environ.get('SUCCESS_RATE', '0.0') or '0.0'
          try:
              success_rate = float(success_rate_str)
          except ValueError:
              success_rate = 0.0
          
          # Get PR details
          pr_number = os.environ['PR_NUMBER']
          repo = os.environ['GITHUB_REPOSITORY']
          token = os.environ['GITHUB_TOKEN']
          
          headers = {
              "Authorization": f"Bearer {token}",
              "Accept": "application/vnd.github+json"
          }
          
          # Get PR title
          try:
              pr_response = requests.get(
                  f"https://api.github.com/repos/{repo}/pulls/{pr_number}",
                  headers=headers,
                  timeout=10
              )
              pr_title = pr_response.json().get('title', 'Unknown PR')
          except:
              pr_title = 'Unknown PR'
          
          # Extract individual test results
          individual_tests = []
          for line in test_results.split('\n'):
              if '::test_' in line and ('PASSED' in line or 'FAILED' in line or 'ERROR' in line):
                  individual_tests.append(line.strip())
          
          # Post to GitHub
          gh_comment = "## üß™ QA Agent Report\n\n"
          gh_comment += "**Automated Test Generation Complete**\n\n"
          gh_comment += "### üìä Test Summary\n"
          gh_comment += f"- **Total Tests:** {total}\n"
          gh_comment += f"- **Passed:** ‚úÖ {passed}\n"
          gh_comment += f"- **Failed:** ‚ùå {failed}\n"
          gh_comment += f"- **Errors:** üî¥ {errors}\n"
          gh_comment += f"- **Success Rate:** {success_rate}%\n\n"
          
          # Add individual test results
          if individual_tests:
              gh_comment += "### üìù Individual Test Results\n"
              for test in individual_tests:
                  if 'PASSED' in test:
                      gh_comment += f"- ‚úÖ `{test.replace('PASSED', '').strip()}`\n"
                  elif 'FAILED' in test:
                      gh_comment += f"- ‚ùå `{test.replace('FAILED', '').strip()}`\n"
                  elif 'ERROR' in test:
                      gh_comment += f"- üî¥ `{test.replace('ERROR', '').strip()}`\n"
              gh_comment += "\n"
          
          gh_comment += "<details>\n<summary>üìã Detailed Results</summary>\n\n```\n"
          gh_comment += test_results[:2000] + "\n```\n</details>\n\n"
          gh_comment += "---\n*Generated by QA Agent*"
          
          try:
              gh_response = requests.post(
                  f"https://api.github.com/repos/{repo}/issues/{pr_number}/comments",
                  headers=headers,
                  json={"body": gh_comment},
                  timeout=30
              )
              
              if gh_response.status_code == 201:
                  print("‚úÖ Posted to GitHub successfully!")
              else:
                  print(f"‚ö†Ô∏è GitHub post failed: {gh_response.status_code}")
          except Exception as e:
              print(f"‚ùå Error posting to GitHub: {e}")
          
          # Post to Notion (if configured) - FIXED VERSION!
          notion_token = os.environ.get('NOTION_TOKEN')
          notion_db = os.environ.get('NOTION_DATABASE_ID')
          
          if notion_token and notion_db:
              print("üìù Posting to Notion with full execution details...")
              
              notion_headers = {
                  "Authorization": f"Bearer {notion_token}",
                  "Content-Type": "application/json",
                  "Notion-Version": "2022-06-28"
              }
              
              # Build content blocks for page body
              content_blocks = []
              
              # Header
              content_blocks.append({
                  "object": "block",
                  "type": "heading_2",
                  "heading_2": {
                      "rich_text": [{"type": "text", "text": {"content": "üß™ QA Test Report"}}]
                  }
              })
              
              # PR info
              content_blocks.append({
                  "object": "block",
                  "type": "paragraph",
                  "paragraph": {
                      "rich_text": [{"type": "text", "text": {"content": f"Pull Request: {pr_title}"}}]
                  }
              })
              
              # GitHub link
              pr_url = f"https://github.com/{repo}/pull/{pr_number}"
              content_blocks.append({
                  "object": "block",
                  "type": "paragraph",
                  "paragraph": {
                      "rich_text": [
                          {"type": "text", "text": {"content": "View PR: "}},
                          {"type": "text", "text": {"content": pr_url, "link": {"url": pr_url}}}
                      ]
                  }
              })
              
              # Divider
              content_blocks.append({
                  "object": "block",
                  "type": "divider",
                  "divider": {}
              })
              
              # Test Summary Header
              content_blocks.append({
                  "object": "block",
                  "type": "heading_3",
                  "heading_3": {
                      "rich_text": [{"type": "text", "text": {"content": "üìä Test Summary"}}]
                  }
              })
              
              # Summary callout with color based on results
              if failed == 0 and errors == 0 and total > 0:
                  callout_color = "green"
                  callout_emoji = "‚úÖ"
              elif success_rate >= 80:
                  callout_color = "yellow"
                  callout_emoji = "‚ö†Ô∏è"
              elif total == 0:
                  callout_color = "gray"
                  callout_emoji = "‚ÑπÔ∏è"
              else:
                  callout_color = "red"
                  callout_emoji = "‚ùå"
              
              summary_text = f"{callout_emoji} Total: {total} | Passed: {passed} | Failed: {failed} | Errors: {errors} | Success Rate: {success_rate}%"
              content_blocks.append({
                  "object": "block",
                  "type": "callout",
                  "callout": {
                      "rich_text": [{"type": "text", "text": {"content": summary_text}}],
                      "icon": {"emoji": "üìà"},
                      "color": callout_color
                  }
              })
              
              # Individual test results section
              if individual_tests:
                  content_blocks.append({
                      "object": "block",
                      "type": "heading_3",
                      "heading_3": {
                          "rich_text": [{"type": "text", "text": {"content": "üîç Individual Test Results"}}]
                      }
                  })
                  
                  for test in individual_tests[:20]:  # Limit to 20 tests to avoid hitting block limits
                      if 'PASSED' in test:
                          test_name = test.replace('PASSED', '').strip()
                          # NO ANNOTATIONS in bulleted_list_item!
                          content_blocks.append({
                              "object": "block",
                              "type": "bulleted_list_item",
                              "bulleted_list_item": {
                                  "rich_text": [{"type": "text", "text": {"content": f"‚úÖ {test_name}"}}],
                                  "color": "green"
                              }
                          })
                      elif 'FAILED' in test:
                          test_name = test.replace('FAILED', '').strip()
                          content_blocks.append({
                              "object": "block",
                              "type": "bulleted_list_item",
                              "bulleted_list_item": {
                                  "rich_text": [{"type": "text", "text": {"content": f"‚ùå {test_name}"}}],
                                  "color": "red"
                              }
                          })
                      elif 'ERROR' in test:
                          test_name = test.replace('ERROR', '').strip()
                          content_blocks.append({
                              "object": "block",
                              "type": "bulleted_list_item",
                              "bulleted_list_item": {
                                  "rich_text": [{"type": "text", "text": {"content": f"üî¥ {test_name}"}}],
                                  "color": "red"
                              }
                          })
                  
                  if len(individual_tests) > 20:
                      content_blocks.append({
                          "object": "block",
                          "type": "callout",
                          "callout": {
                              "rich_text": [{"type": "text", "text": {"content": f"... and {len(individual_tests) - 20} more tests. See full output below."}}],
                              "icon": {"emoji": "‚ÑπÔ∏è"}
                          }
                      })
              
              # Test breakdown header
              content_blocks.append({
                  "object": "block",
                  "type": "divider",
                  "divider": {}
              })
              
              content_blocks.append({
                  "object": "block",
                  "type": "heading_3",
                  "heading_3": {
                      "rich_text": [{"type": "text", "text": {"content": "üìã Test Execution Steps"}}]
                  }
              })
              
              content_blocks.append({
                  "object": "block",
                  "type": "paragraph",
                  "paragraph": {
                      "rich_text": [{"type": "text", "text": {"content": "Here's exactly what the QA agent did:"}}]
                  }
              })
              
              # Parse execution log and add steps
              steps = execution_log.split('Step ')
              for i, step in enumerate(steps[1:], 1):  # Skip first empty element
                  if step.strip() and len(content_blocks) < 80:  # Limit blocks
                      step_lines = step.strip().split('\n')
                      step_title = step_lines[0].strip().rstrip(':')
                      
                      # Add numbered step (use paragraph instead of formatted text)
                      content_blocks.append({
                          "object": "block",
                          "type": "paragraph",
                          "paragraph": {
                              "rich_text": [{"type": "text", "text": {"content": f"{i}. {step_title}"}}]
                          }
                      })
                      
                      # Add step details if any (limit to prevent block overflow)
                      if len(step_lines) > 1 and len(content_blocks) < 85:
                          step_content = '\n'.join(step_lines[1:5])  # First 4 detail lines
                          if step_content.strip():
                              content_blocks.append({
                                  "object": "block",
                                  "type": "quote",
                                  "quote": {
                                      "rich_text": [{"type": "text", "text": {"content": step_content[:1000]}}],
                                      "color": "gray"
                                  }
                              })
              
              # Divider before metadata
              content_blocks.append({
                  "object": "block",
                  "type": "divider",
                  "divider": {}
              })
              
              # Metadata section
              content_blocks.append({
                  "object": "block",
                  "type": "heading_3",
                  "heading_3": {
                      "rich_text": [{"type": "text", "text": {"content": "üìã Metadata"}}]
                  }
              })
              
              # PR Number (simple text, no annotations)
              content_blocks.append({
                  "object": "block",
                  "type": "bulleted_list_item",
                  "bulleted_list_item": {
                      "rich_text": [{"type": "text", "text": {"content": f"PR Number: #{pr_number}"}}]
                  }
              })
              
              # Repository
              content_blocks.append({
                  "object": "block",
                  "type": "bulleted_list_item",
                  "bulleted_list_item": {
                      "rich_text": [{"type": "text", "text": {"content": f"Repository: {repo}"}}]
                  }
              })
              
              # Timestamp
              timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')
              content_blocks.append({
                  "object": "block",
                  "type": "bulleted_list_item",
                  "bulleted_list_item": {
                      "rich_text": [{"type": "text", "text": {"content": f"Generated: {timestamp}"}}]
                  }
              })
              
              # Test output section (if available and space permits)
              if test_results and test_results != "No test results available" and len(content_blocks) < 90:
                  content_blocks.append({
                      "object": "block",
                      "type": "divider",
                      "divider": {}
                  })
                  
                  content_blocks.append({
                      "object": "block",
                      "type": "heading_3",
                      "heading_3": {
                          "rich_text": [{"type": "text", "text": {"content": "üìÑ Full Test Output"}}]
                      }
                  })
                  
                  # Truncate test results to fit Notion's limits (2000 chars per block)
                  truncated_results = test_results[:1800] if len(test_results) > 1800 else test_results
                  
                  if len(test_results) > 1800:
                      content_blocks.append({
                          "object": "block",
                          "type": "callout",
                          "callout": {
                              "rich_text": [{"type": "text", "text": {"content": "‚ö†Ô∏è Output truncated - view full results on GitHub"}}],
                              "icon": {"emoji": "‚ö†Ô∏è"},
                              "color": "yellow"
                          }
                      })
                  
                  content_blocks.append({
                      "object": "block",
                      "type": "code",
                      "code": {
                          "rich_text": [{"type": "text", "text": {"content": truncated_results}}],
                          "language": "plain text"
                      }
                  })
              
              # Create the page with properties AND content
              notion_data = {
                  "parent": {"database_id": notion_db},
                  "properties": {
                      "Name": {
                          "title": [{"text": {"content": f"QA Report: {pr_title[:70]} ({success_rate}%)"}}]
                      },
                      "Agent Type": {
                          "select": {"name": "QA"}
                      },
                      "Issue/PR Number": {
                          "number": int(pr_number)
                      },
                      "Status": {
                          "select": {"name": "Complete"}
                      }
                  },
                  "children": content_blocks[:100]  # Notion limit: 100 blocks per request
              }
              
              try:
                  notion_response = requests.post(
                      "https://api.notion.com/v1/pages",
                      headers=notion_headers,
                      json=notion_data,
                      timeout=30
                  )
                  
                  if notion_response.status_code == 200:
                      print(f"‚úÖ Posted to Notion successfully with execution details!")
                      print(f"   Tests: {passed}/{total} passed")
                      print(f"   Content blocks: {len(content_blocks[:100])}")
                      print(f"   Individual tests shown: {len(individual_tests)}")
                  else:
                      print(f"‚ö†Ô∏è Notion post failed: {notion_response.status_code}")
                      print(f"   Response: {notion_response.text[:500]}")
              except Exception as e:
                  print(f"‚ùå Error posting to Notion: {e}")
          else:
              print("‚ÑπÔ∏è Notion not configured - skipping")
          
          print("\n" + "="*60)
          print("üìä Summary")
          print(f"   Total: {total} | Passed: {passed} | Failed: {failed} | Errors: {errors}")
          print(f"   Success Rate: {success_rate}%")
          print("="*60)
          
          PYTHON_SCRIPT
